## 自瞄代码详解文档

> 1.0代码更新
>
> ​	1、NX忘记打开摄像头
>
> ​	2、大装甲板距离计算参数忘记乘一个放大系数



头文件就不说了，配置opencv和基本的c++库函数头文件

```
//#define NX
#define RED
//#define BLUE
//#define IMSHOW //提高效率可以把这两个注释掉
#define CLOCK
//#define PREDICT

#ifdef NX
#include "serial.h"
#endif
```

NX是在英伟达nx上运行时和电控对接的一些代码

RED/BLUE这个就是需要识别的红蓝色装甲板

IMSHOW是打开调试的图像显示

CLOCK是打开运行一次代码所需的时间

PREDICT是开启卡尔曼预测

serial.h是使用USB口进行数据传输的头文件



```
#ifdef NX
    Serial uart(BR115200, WORDLENGTH_8B, STOPBITS_1, PARITY_NONE, HWCONTROL_NONE);
    uart.sOpen("/dev/ttyUSB0");
    VideoCapture capture(0);
#endif
    clock_t start, finish;
    double totaltime, heights[32],sum=0;
    int hi = 0;
    int times = 0;

#ifndef NX
    VideoCapture capture(1);
#endif
```

打开摄像头和定义一些基础变量



```
    Mat frame, binary, frame1;
    RotatedRect Select_contours[32];
    RotatedRect RA[32], R[32];
    int stateNum = 4;
    int measureNum = 2;
```

定义一些图像处理要用到的变量

**接下来的KF代码部分看文末卡尔曼滤波部分**



```
        hi = 0;//再次确保不会爆数组
#ifdef CLOCK
        start = clock();
#endif
        capture >> frame;
        frame.copyTo(binary);//展示效果
        frame.copyTo(frame1);
        //cvtColor(frame1, frame1, COLOR_BGR2HSV);//用作后面的红蓝判断
        if (!capture.isOpened()) break;
```

hi是统计得到多少个装甲板的，在每一次处理图像前需要置零

capture是把图像读入到frame的Mat对象中

if判断是为了当摄像头打不开的时候退出程序通过自启动重开程序



```
        //HSV方案
        Mat temp, temp1,temp2, thres_whole;
        cvtColor(frame, temp, COLOR_BGR2HSV);
        inRange(temp, Scalar(0,43,46),Scalar(11,255,255),temp1);
        inRange(temp,Scalar(156,43,46),Scalar(181,255,255),temp2);
        Mat red;
        red = temp2 | temp1;
        cvtColor(frame,thres_whole,CV_BGR2GRAY);
        threshold(thres_whole,thres_whole,105,255,THRESH_BINARY);

        frame = red & thres_whole;
        imshow("1", frame);
```

HSV方案 思路是通过判断HSV颜色分量是否在红色或者蓝色范围之中

inRange两次是因为红色的HSV值有两段

red = temp2 | temp1;把两个图像或一下，得到所有红色的部分

frame = red & thres_whole;把两个图像和一下，得到红色并且亮的部分

**HSV的缺陷是慢，在技术原理上是比RGB要稳定的，但是深大用的是RGB方案，因为别人用的是工业摄像头，比较好，不需要过多考虑稳定性**



        //RGB方案
        //blue
        Mat thres_whole;
        vector<Mat> splited;
        split(frame, splited);
        cvtColor(frame, thres_whole, CV_BGR2GRAY);
        threshold(thres_whole, thres_whole, 128, 255, THRESH_BINARY);
    
        subtract(splited[0], splited[2], frame);
        cvtColor(frame, frame, COLOR_BGR2GRAY);
        threshold(frame, frame, 90, 255, THRESH_BINARY);// blue
    
        frame = frame & thres_whole;
        imshow("1", frame);
RGB方案 思路是通过红色通道和蓝色通道相减判断蓝色通道大还是红色通道大得出图像部分是蓝色还是红色，然后通过二值化得到亮的部分

先二值化得到亮的图thres_whole

subtract(splited[0], splited[2], frame);b通道减r通道，如果是蓝色部分那么得到的每一个数值应该是正数，如果是红色图那么得到的数值应该都是0

frame = frame & thres_whole;把两个图像和一下，得到蓝色并且亮的部分

**RGB方案的缺陷是容易受到摄像头拍摄的图像干扰，速度较快，在摄像头允许情况下尽可能用RGB方案**



```
		//亮度方案
        float Image_bright = -102;
        Mat BrightnessLut(1, 256, CV_8UC1);
        for (int i = 0; i < 256; i++)
        {//you can change "Image_bright" to adjust bright level
            BrightnessLut.at<uchar>(i) = saturate_cast<uchar>(i + Image_bright);
        }
        LUT(frame, BrightnessLut, frame);
        cvtColor(frame, frame, COLOR_BGR2GRAY);
        int threshold_value = 105;
        threshold(frame, frame, threshold_value, 255, cv::THRESH_BINARY);
```

实话实说，这是一个没有卵用的方案，因为没有办法判断红色和蓝色

但是你们实在做不出来，可以在摄像头上加装红色或者蓝色的滤光片，然后强行上这个方案

BrightnessLut是一个亮度查找表，构造一个亮度减少的数值

LUT通过亮度查找表使得图像上每一个点的亮度减少一个值

得到一个只有亮的部分的图片，再二值化就很清晰了



```
 Mat kernel = getStructuringElement(MORPH_ELLIPSE, Size(3, 3), Point(-1, -1));
        morphologyEx(frame, frame, MORPH_OPEN, kernel);
```

形态学操作

getStructuringElement得到形状和尺寸的结构元素

morphologyEx形态学开操作，先腐蚀再膨胀，可以有效除去过小的噪点



```
        vector<vector<Point>> contours;
        findContours(frame, contours, RETR_LIST, CHAIN_APPROX_NONE);
        vector<vector<Point>> select_contours;
```

定义两个容器套容器，一个是框的点集，另外一个是通过第一次筛选的框的点集

findContours找出所有处理完后图片的框



```
        for (size_t i = 0; i < contours.size(); i++)
        {
            float light_contour_area = contourArea(contours[i]);

            if (light_contour_area < 20 || contours[i].size() <= 5)
            {
                continue;
            }

            drawContours(frame, contours, static_cast<int>(i), Scalar(0), 2);

            //RotatedRect rec = fitEllipse(contours[i]); //椭圆拟合
            RotatedRect rec = minAreaRect(contours[i]); //最小外接矩阵拟合
```

contourArea得到框中间面积的大小

light_contour_area < 20 判断面积的大小是否过小，过小就进行对下一个框的操作

contours[i].size() <= 5 判断框的点集点的个数，如果点少于等于5个就跳出

drawContours画出剩下的轮廓，不过这个函数好像没什么用

因为有的灯条亮有的灯条暗，如果采用椭圆拟合出来的矩形大小就会相差比较大，而最小外接矩形比较相似



```
            float angle = abs(rec.angle);
            if (angle > 45)
            {
                angle = 90 - angle;
            }
            if (angle > 30)
            {
                continue;
            }
```

判断矩形是否过于倾斜，如果倾角绝对值大于30度这个矩形就不要了

**请记住下面这张图片**

![微信图片_20210418224206](.\微信图片_20210418224206.jpg)



            const float width_height_ratio_max = 10;
            const float width_height_ratio_min = 2;
            if (abs(rec.angle) < 45)
            {
                if ((rec.size.height / rec.size.width) > width_height_ratio_max)
                {
                    continue;
                }
            }
            else
            {
                if ((rec.size.width / rec.size.height) > width_height_ratio_max)
                {
                    continue;
                }
            }
            select_contours.push_back(contours[i]);
通过角度得知矩形是向左还是向右倾斜

然后通过实际的长款比判断矩形是否过方或者过宽，就不要

然后把通过判断没有筛掉的矩形放进select_contours里面



        for (int i = 0; i < select_contours.size(); i++)
        {
    
            drawContours(frame, select_contours, static_cast<int>(i), Scalar(0), 2);
    
            if (i == select_contours.size() - 1) continue;
            RotatedRect rect = minAreaRect(select_contours[i]);
    
            for (int j = i + 1; j < select_contours.size(); j++)
            {
                RotatedRect rectA = minAreaRect(select_contours[j]);
这一部分使找到的矩形配对，同时通过两个for避免自身配对



                float r_angle, rA_angle, angle_diff;
                float r_height, r_width, rA_height, rA_width;
                float r_ratio, rA_ratio;
                if (rect.angle < -45)
                {
                    r_angle = 90 + rect.angle;
                    r_width = rect.size.height;
                    r_height = rect.size.width;
                }
                else 
                {
                    r_angle = rect.angle;
                    r_height = rect.size.height;
                    r_width = rect.size.width;
                }
                if (rectA.angle < -45)
                {
                    rA_angle = 90 + rectA.angle;
                    rA_width = rectA.size.height;
                    rA_height = rectA.size.width;
                }
                else
                {
                    rA_angle = rectA.angle;
                    rA_height = rectA.size.height;
                    rA_width = rectA.size.width;
                }
                r_ratio = r_height / r_width;
                rA_ratio = rA_height / rA_width;
                if (r_ratio > 10 || r_ratio < 1 || rA_ratio> 10 || rA_ratio < 1)
                {
                    //cout << r_ratio << "   " << rA_ratio << endl;;
                    continue;
                }
    
                angle_diff = abs(r_angle - rA_angle);
                if (angle_diff > 10)
                {
                    continue;
                }
这一部分是再一次判断长宽比，同时使向左的矩形偏角为正，向右的矩形偏角为负，作差得到差值小于10，严格一点调成5也行，太严格可能会在快速运动时误判

通过这种方法，可以同时适用平行灯条、内八字和外八字灯条



                float d = sqrt((rect.center.x - rectA.center.x) * (rect.center.x - rectA.center.x) +
                    (rect.center.y - rectA.center.y) * (rect.center.y - rectA.center.y));
                if (abs(rect.center.x - rectA.center.x) < 0.9 * d)
                {
                    continue;
                }
![微信图片_20210418225735](.\微信图片_20210418225735.jpg)

不解释



                const float twobar_height_ratio_max = 3;
                float twobar_height_ratio = max(max(rect.size.width, rect.size.height), max(rectA.size.width, rectA.size.height)) / min(max(rect.size.width, rect.size.height), max(rectA.size.width, rectA.size.height));
                float twobar_width_ratio = max(min(rect.size.width, rect.size.height), min(rectA.size.width, rectA.size.height)) / min(min(rect.size.width, rect.size.height), min(rectA.size.width, rectA.size.height));;
    
                if (twobar_width_ratio > twobar_height_ratio_max || twobar_height_ratio > twobar_height_ratio_max)
                {
                    continue;
                }
                if (rect.size.area() / rectA.size.area() > 3)
                {
                    continue;
                }
第一个判断是两个灯条互相的长度比值、互相的宽度比值

第二个判断是两个矩形的面积比值，这个数值不要调太小



                float board_width = abs(rect.center.x - rectA.center.x);
                float board_height = (max(rect.size.width, rect.size.height) + max(rectA.size.width, rectA.size.height)) / 2;
                float board_ratio = board_width / board_height;
                const float board_ratio_max = 7;
                if (board_ratio > board_ratio_max)
                {
                    continue;
                }
装甲板的宽长判断，避免两个很远的灯条也被识别成装甲板，这个数值不要调太大



                float board_width_difference = abs(rect.center.x - rectA.center.x);
                float board_height_difference = abs(rect.center.y - rectA.center.y);
    
                const float board_height_difference_max = 200;
                const float board_width_difference_min = 30;
                if (board_width_difference < board_width_difference_min || board_height_difference>board_height_difference_max)
                {
                    continue;
                }
再判断一次两个矩形的中心x坐标差值和y坐标差值



                heights[hi] = max(rect.size.height,rect.size.width)+ max(rectA.size.height,rectA.size.width) / 2;
                R[hi] = rect;
                RA[hi] = rectA;
                hi++;//统计找到的装甲板个数
heights[hi]这个是存储灯条高度，灯条高度最大意味着装甲板越靠近

R[hi]和RA[hi]存储装甲板对应灯条的矩形



        //选择最近的装甲板进行击打
        double maxh = 0;
        int mark;
        for (int i = 0; i < hi; i++)
        {
            if (heights[i] >= maxh)
            {
                maxh = heights[i];
                mark = i;
            }
        }
找到最近的装甲板作为目标



            cv::circle(binary, Point((R[mark].center.x + RA[mark].center.x) / 2,
                (R[mark].center.y + RA[mark].center.y) / 2),
                15, cv::Scalar(0, 0, 255), 4);
找到装甲板中心画圆



            Point2f verticesR[4];
            R[mark].points(verticesR);
            Point2f verticesRA[4];
            RA[mark].points(verticesRA);
            float x1, y1, x2, y2, x3, y3, x4, y4;
    
            if (abs(R[mark].angle) > 45)
            {
                x1 = (verticesR[2].x + verticesR[3].x) / 2;
                y1 = (verticesR[2].y + verticesR[3].y) / 2;
                x4 = (verticesR[1].x + verticesR[0].x) / 2;
                y4 = (verticesR[1].y + verticesR[0].y) / 2;
            }
            else
            {
                x1 = (verticesR[1].x + verticesR[2].x) / 2;
                y1 = (verticesR[1].y + verticesR[2].y) / 2;
                x4 = (verticesR[0].x + verticesR[3].x) / 2;
                y4 = (verticesR[0].y + verticesR[3].y) / 2;
            }
    
            if (abs(RA[mark].angle) > 45)
            {
                x2 = (verticesRA[2].x + verticesRA[3].x) / 2;
                y2 = (verticesRA[2].y + verticesRA[3].y) / 2;
                x3 = (verticesRA[1].x + verticesRA[0].x) / 2;
                y3 = (verticesRA[1].y + verticesRA[0].y) / 2;
            }
            else
            {
                x2 = (verticesRA[1].x + verticesRA[2].x) / 2;
                y2 = (verticesRA[1].y + verticesRA[2].y) / 2;
                x3 = (verticesRA[0].x + verticesRA[3].x) / 2;
                y3 = (verticesRA[0].y + verticesRA[3].y) / 2;
            }
![微信图片_20210418224206](.\微信图片_20210418224206.jpg)

记得这张图片吗？

这里就是通过8个点的坐标算出4个点的坐标

**为什么要这样做呢？**

因为灯条的上下边中心点可以消除摄像头带来的灯条矩形误差，尽最大可能拟合出装甲板的真正形状，看图

![微信图片_20210418231411](.\微信图片_20210418231411.jpg)

这个四个点的坐标越接近实际装甲板的形状，后面的角度计算就越精确



            float boardw_up = sqrt((x1 - x2) * (x1 - x2) + (y1 - y2) * (y1 - y2));
            float boardw_down = sqrt((x3 - x4) * (x3 - x4) + (y3 - y4) * (y3 - y4));
            float boardw = (boardw_up + boardw_down) / 2;
            float boardh_left = sqrt((x1 - x4) * (x1 - x4) + (y1 - y4) * (y1 - y4));
            float boardh_right = sqrt((x2 - x3) * (x2 - x3) + (y2 - y3) * (y2 - y3));
            float boardh = (boardh_left + boardh_right) / 2;
    
            float board_width = abs(R[mark].center.x - RA[mark].center.x);
            float board_height = (max(R[mark].size.width, R[mark].size.height) + max(RA[mark].size.width, RA[mark].size.height)) / 2;
            float board_ratio = board_width / board_height;
            float xishu;
            float final_distance;
            if (board_ratio < 4)//判断是大装甲板还是小装甲板
            {
                //小装甲板
                xishu = (13.5 / boardw + 5.4 / boardh) / 2;
                final_distance = 10700 / boardw;
            }
            else 
            {
                //大装甲板
                xishu = (23.5 / boardw + 5.4 / boardh) / 2;
                final_distance = 18626 / boardw;
            }
这部分可能会看得很晕

boardw和board_width本质上是同一个东西

boardh和board_height也一样

但是用了两种算法

board_width和board_height只是用于粗略地判断装甲板的大小

boardw和boardh用于计算角度，相对精确

实际距离是真实世界的距离，图像距离是图片上的距离

**xishu是通过实际装甲板大小除以图像上装甲板大小得到的一个值，这个值乘以图像上的距离能够得到在装甲板平面上的实际距离**

**final_distance是通过图像上的板宽除以一个定值得到摄像头和装甲板的实际距离**



            double distance_to_midboard_x, distance_to_midboard_y;
            distance_to_midboard_x = xishu * (center_x - 320);
            distance_to_midboard_y = xishu * (center_y - 160);
    
            double angle_x = atan2(distance_to_midboard_x, final_distance);
            double angle_y = atan2(distance_to_midboard_y, final_distance);
    
            const double P = 3.1415926;
            double final_angle_x = angle_x / P * 180;
            double final_angle_y = angle_y / P * 180;
使用系数得到实际距离

通过arctan函数得到x方向和y方向上的弧度

乘以pi得到角度，然后发送

```
        hi = 0;//这个很重要！！！ 让RotatedRect数组重新从0开始存储 不然会爆数组
```

让hi（找到的装甲板数）置零，不然数组仍然保存上一帧识别到的装甲板，不仅会爆数组，而且会识别到不存在的装甲板





**卡尔曼滤波部分**

实话实说，视觉做出来的卡尔曼不够稳定，而且会有很多失误

电控做预测会使云台运动更加的平滑

电控一秒能处理几百次，而视觉一秒处理几十次，这样对单视觉预测的精度要求太高，太过于困难



代码里面用的卡尔曼是照着这个写的：

https://blog.csdn.net/kingcooper/article/details/50817586

卡尔曼滤波加速度补充：

https://wenku.baidu.com/link?url=8coPyaynBWaTWxS2PzcLKF0Is7eELFo_XwDjDu-X5cHF9IzXDcp2Ifc730Nwkn0zWGqm1CD213nPXOR2SGShf1eHA89CV5B_YrDDNcMAMve 



